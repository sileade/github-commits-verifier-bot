# ðŸš€ Complete Automated Docker Setup Guide

## Overview

This guide covers the **fully automated setup** with zero manual configuration needed. Everything is built into the docker-compose and startup scripts.

### What Gets Set Up

- ðŸ’¾ **PostgreSQL 16** - Database with automatic initialization
- ðŸ¤– **Ollama** - Optional local LLM (Mistral, Llama2, etc.)
- ðŸ“„ **GitHub Commits Bot** - Main application
- ðŸ”’ **Health Checks** - Automatic service verification
- ðŸ“ **Logging** - Centralized container logs
- ðŸ“¤ **Resource Limits** - Memory and CPU constraints
- ðŸ” **Security** - Non-root user, no new privileges

---

## Quick Start (3 Commands!)

```bash
# 1. Setup configuration (Telegram + GitHub tokens)
./setup.sh

# 2. Make startup script executable
chmod +x start.sh

# 3. Start everything (fully automated!)
./start.sh
```

That's it! ðŸŒŸ

---

## Detailed Setup Process

### Step 1: Initial Configuration

```bash
./setup.sh
```

**This script:**
- âœ… Checks Docker installation
- âœ… Generates secure PostgreSQL password
- âœ… Creates `.env` file
- âœ… Prompts for Telegram Bot Token
- âœ… Prompts for GitHub Personal Access Token
- âœ… Optionally prompts for OpenAI API Key
- âœ… Validates all configuration

**Output:**
```
âœ“ Docker installed
âœ“ Docker Compose installed
âœ“ OpenSSL installed
âœ“ PostgreSQL password generated
âœ“ .env file created
? Enter your Telegram Bot Token: [input]
âœ“ Telegram Bot Token saved
? Enter your GitHub Personal Access Token: [input]
âœ“ GitHub Token saved

===== Setup Complete! =====
Next: chmod +x start.sh && ./start.sh
```

### Step 2: Start All Services

```bash
chmod +x start.sh
./start.sh
```

**This script automatically:**

1. ðŸ³ **Validates Environment**
   - Checks .env file exists
   - Verifies required tokens are set
   - Detects if local LLM is enabled

2. ðŸ³ **Checks Docker**
   - Verifies Docker is installed
   - Confirms Docker daemon is running

3. ðŸ“‚ **Builds Image**
   - Rebuilds Docker image with all dependencies
   - Uses optimized multi-stage build
   - Takes 2-5 minutes (cached after first run)

4. ðŸš€ **Starts Services**
   - PostgreSQL starts first
   - Ollama starts (if enabled)
   - Bot starts after dependencies are ready

5. â³ **Waits for Health**
   - Verifies PostgreSQL is ready
   - Checks Ollama health (if enabled)
   - Confirms bot is running

6. ðŸ¤– **Initializes LLM** (if enabled)
   - Checks if model is loaded
   - Pulls model if needed (first run: 5-15 minutes)
   - Verifies model is ready

7. ðŸŒŸ **Shows Status & Instructions**

**Expected Output:**
```
==================================================
ðŸ¤– GitHub Commits Verifier Bot - Complete Startup
==================================================

âœ“ .env file found
âœ“ TELEGRAM_BOT_TOKEN configured
âœ“ GITHUB_TOKEN configured
âœ“ Local LLM (Ollama) enabled

==================================================
ðŸ³ Docker Check
==================================================

âœ“ Docker installed
âœ“ Docker daemon running

==================================================
ðŸ³ Building Docker Image
==================================================

âœ“ Docker image built successfully

==================================================
ðŸš€ Starting Services
==================================================

âœ” Starting PostgreSQL...
âœ“ PostgreSQL started
âœ” Starting Ollama...
âœ“ Ollama started
âœ” Starting GitHub Commits Bot...
âœ“ Bot started

==================================================
â³ Waiting for Services
==================================================

âœ“ PostgreSQL is healthy
âœ“ Ollama is healthy
âœ“ Bot is running

==================================================
ðŸ¤– Initializing Local LLM Model
==================================================

âœ“ Model 'mistral' is already loaded

==================================================
ðŸŒŸ Setup Complete!
==================================================

All services are running and healthy!
...
```

---

## Automated docker-compose Features

### Health Checks

Each service has automatic health checks:

```yaml
# PostgreSQL
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U github_bot"]
  interval: 10s
  timeout: 5s
  retries: 5

# Ollama
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  interval: 10s
  timeout: 5s
  retries: 5

# Bot
healthcheck:
  test: ["CMD", "python", "-c", "print('Bot running')"]
  interval: 30s
  timeout: 10s
  retries: 3
```

**Docker automatically:**
- âœ… Monitors service health
- âœ… Restarts unhealthy containers
- âœ… Manages dependencies (bot waits for postgres + ollama)

### Resource Limits

Each service has defined resource limits:

```yaml
PostgreSQL:
  CPU: 1 core (limit), 0.5 core (reservation)
  RAM: 512 MB (limit), 256 MB (reservation)

Ollama:
  CPU: 2 cores (limit), 1 core (reservation)
  RAM: 8 GB (limit), 4 GB (reservation)

Bot:
  CPU: 1 core (limit), 0.5 core (reservation)
  RAM: 512 MB (limit), 256 MB (reservation)
```

### Networking

```yaml
networks:
  bot_network:
    driver: bridge
    subnet: 172.28.0.0/16
```

**Services communicate via:**
- `postgres:5432` - Database
- `ollama:11434` - Local LLM API
- Internal network isolation

### Volumes

```yaml
volumes:
  postgres_data:      # Database persistence
  ollama_data:        # Model cache
  ./logs:/app/logs    # Application logs (local mount)
  ./.env:/app/.env:ro # Configuration (read-only)
```

---

## Useful Commands

### View Status

```bash
# See all running services
docker-compose ps

# Output:
# NAME                      STATUS
# github-commits-postgres   Up (healthy)
# ollama                    Up (healthy)
# github-commits-verifier-bot  Up (healthy)
```

### View Logs

```bash
# Bot logs (real-time)
./start.sh  # Then in another terminal:
docker-compose logs -f github-commits-bot

# Database logs
docker-compose logs -f postgres

# Ollama logs
docker-compose logs -f ollama

# All logs
docker-compose logs -f

# Last 50 lines
docker-compose logs --tail=50

# Search logs
docker-compose logs | grep -i error
```

### Restart Services

```bash
# Graceful restart (recommended)
./restart.sh

# Or manually
docker-compose down
docker-compose up -d

# Restart specific service
docker-compose restart github-commits-bot
```

### Stop Services

```bash
# Graceful shutdown
./stop.sh

# Or manually
docker-compose down

# With volume cleanup (WARNING: removes data!)
docker-compose down -v
```

### Database Access

```bash
# Connect to PostgreSQL
docker exec -it github-commits-postgres psql -U github_bot -d github_verifier

# Backup database
docker exec github-commits-postgres pg_dump -U github_bot github_verifier > backup.sql

# Check database size
docker exec -it github-commits-postgres psql -U github_bot -d github_verifier \
  -c "SELECT pg_size_pretty(pg_database_size('github_verifier'));"
```

### Ollama Management (if enabled)

```bash
# List loaded models
docker exec ollama ollama list

# Pull another model
docker exec ollama ollama pull llama2

# Run a model interactively
docker exec ollama ollama run mistral "What is 2+2?"

# View Ollama logs
docker logs -f ollama
```

### Bot Management

```bash
# Execute Python command in bot
docker exec github-commits-bot python -c "print('test')"

# Enter bot container shell
docker exec -it github-commits-bot /bin/bash

# Rebuild bot image without cache
docker-compose build --no-cache github-commits-bot
docker-compose up -d
```

---

## Configuration Options

### Enable Local LLM (Ollama)

In `.env`:

```env
USE_LOCAL_MODEL=true
OLLAMA_HOST=http://ollama:11434
LOCAL_MODEL=mistral  # or llama2, neural-chat, dolphin-mixtral, etc.
```

On next `./start.sh`, it will:
- âœ… Start Ollama container
- âœ… Pull the specified model
- âœ… Configure bot to use local LLM

### Enable GPU Support (NVIDIA)

Uncomment in `docker-compose.yml` under `ollama` service:

```yaml
# Uncomment for GPU support (NVIDIA CUDA)
runtime: nvidia
environment:
  - NVIDIA_VISIBLE_DEVICES=all
```

Then:
```bash
docker-compose build --no-cache
./start.sh
```

**Speed improvement:**
- CPU: 5-30 seconds per analysis
- GPU: <5 seconds per analysis (10x faster!)

### Change Model

```bash
# Update .env
LOCAL_MODEL=llama2

# Restart
./restart.sh
```

Model will be automatically pulled on next startup.

### Disable Components

**Disable local LLM:**
```env
USE_LOCAL_MODEL=false
```

**Disable Ollama container (faster startup):**
```yaml
# In docker-compose.yml, comment out ollama service
# ollama:  # DISABLED
#   image: ...
```

Then remove from bot depends_on:
```yaml
depends_on:
  postgres:
    condition: service_healthy
  # ollama:  # REMOVED
  #   condition: service_healthy
```

---

## Troubleshooting

### "Container exits immediately"

```bash
# Check logs
docker-compose logs --tail=20 github-commits-bot

# Verify .env is valid
cat .env | grep TELEGRAM_BOT_TOKEN

# Rebuild without cache
docker-compose build --no-cache
./start.sh
```

### "PostgreSQL won't start"

```bash
# Check PostgreSQL logs
docker-compose logs postgres

# Verify volume
docker volume ls | grep postgres

# Remove corrupted volume and restart
docker volume rm github-commits-bot_postgres_data
./start.sh
```

### "Ollama timeout"

```bash
# Check if model is downloading
docker logs -f ollama

# Increase timeout or wait longer
# First model pull takes 5-15 minutes

# Manually pull model
docker exec ollama ollama pull mistral
```

### "Bot can't connect to database"

```bash
# Check if PostgreSQL is healthy
docker-compose ps postgres

# Check connection string
grep DATABASE_URL .env

# Manual test
docker exec -it github-commits-postgres psql -U github_bot -d github_verifier -c "SELECT 1"
```

### "Out of memory"

```bash
# Check memory usage
docker stats

# Reduce resource limits in docker-compose.yml
# Or use smaller model
LOCAL_MODEL=openchat  # 3.5B instead of 7B

# Or add swap
# See your OS documentation for adding swap
```

---

## Full Workflow Example

### First Time Setup

```bash
# Clone repository
git clone https://github.com/sileade/github-commits-verifier-bot.git
cd github-commits-verifier-bot

# Run setup (interactive)
./setup.sh
# Follow prompts:
# - Enter Telegram Bot Token
# - Enter GitHub Personal Access Token
# - (Optional) Enter OpenAI API Key
# - (Optional) Enable local LLM

# Make scripts executable
chmod +x start.sh stop.sh restart.sh

# Start everything (fully automatic!)
./start.sh
# This will:
# - Build Docker image
# - Start PostgreSQL
# - Start Ollama (if enabled)
# - Start bot
# - Wait for all services to be healthy
# - Show status and next steps
```

### Daily Usage

```bash
# Check status
docker-compose ps

# View logs
docker-compose logs -f github-commits-bot

# Stop for the day
./stop.sh
```

### Restart/Update

```bash
# Restart all services
./restart.sh

# Update code
git pull origin main

# Rebuild and restart
docker-compose build --no-cache
./start.sh
```

---

## Security Considerations

âœ… **Implemented:**
- Non-root user execution (UID 1000)
- No new privileges flag
- Read-only .env mount
- Private network (bot_network)
- Health checks
- Resource limits
- Proper signal handling (SIGTERM)

âš ï¸ **Remember:**
- Keep `.env` file private (has tokens!)
- Use strong PostgreSQL password
- Keep tokens in `.env` only, never in code
- Regularly backup database

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Docker-Compose Network (172.28.0.0/16)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚  â”‚  PostgreSQL  â”‚  â”‚  Ollama  â”‚  â”‚ Bot â”‚
â”‚  â”‚    :5432     â”‚  â”‚ :11434   â”‚  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
â”‚        â–²                â–²            â–²   â”‚
â”‚        â”‚                â”‚            â”‚   â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                â”‚
â”‚                    (localhost)            â”‚
â”‚                   (Host machine)          â”‚
â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Organization

```
github-commits-verifier-bot/
â”œâ”€â”€ start.sh              # â­ Main startup script
â”œâ”€â”€ stop.sh               # Shutdown script
â”œâ”€â”€ restart.sh            # Restart script
â”œâ”€â”€ setup.sh              # Initial configuration
â”œâ”€â”€ docker-compose.yml    # â­ Full stack definition
â”œâ”€â”€ Dockerfile            # â­ Multi-stage build
â”œâ”€â”€ .env                  # Configuration (auto-generated)
â”œâ”€â”€ .env.example          # Template
â”œâ”€â”€ bot.py                # Bot application
â”œâ”€â”€ github_service.py     # GitHub integration
â”œâ”€â”€ database.py           # PostgreSQL async driver
â”œâ”€â”€ ai_analyzer.py        # OpenAI integration
â”œâ”€â”€ local_analyzer.py     # Ollama integration
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # Main documentation
â””â”€â”€ logs/                 # Application logs
    â””â”€â”€ bot.log
```

---

## Performance Tuning

### Faster Startup

```bash
# Disable local LLM if not needed
USE_LOCAL_MODEL=false

# Or use smaller model
LOCAL_MODEL=openchat  # 3.5B (2 seconds)
```

### Better Performance

```bash
# Enable GPU
# In docker-compose.yml:
runtime: nvidia

# Use faster model
LOCAL_MODEL=mistral  # 7B (5 seconds)
```

### Production-Ready

```bash
# Use highest quality
LOCAL_MODEL=llama2:13b  # 13B (10 seconds)
# Or
OPENAI_API_KEY=sk-...   # Cloud (2-5 seconds)
```

---

## Next Steps

1. âœ… Run `./setup.sh`
2. âœ… Run `./start.sh`
3. âœ… Open Telegram, find your bot
4. âœ… Send `/start`
5. âœ… Try checking your first commit!

**Happy verifying!** ðŸš€

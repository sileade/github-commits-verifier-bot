# ============================================================================
# GitHub Commits Verifier Bot - Configuration File
# ============================================================================
# This file contains all environment variables required for the bot to run.
# Auto-generated by setup.sh - edit values as needed.
# ============================================================================

# TELEGRAM BOT CONFIGURATION
# Get your token from @BotFather on Telegram (https://t.me/botfather)
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# GITHUB CONFIGURATION  
# Get your Personal Access Token from GitHub Settings > Developer Settings
# Required scopes: repo, read:user
GITHUB_TOKEN=your_github_personal_access_token_here

# DATABASE CONFIGURATION (PostgreSQL)
# Auto-generated by setup.sh
POSTGRES_DB=github_verifier
POSTGRES_USER=github_bot
POSTGRES_PASSWORD=changeme_secure_password_12345
DATABASE_URL=postgresql://github_bot:changeme_secure_password_12345@postgres:5432/github_verifier

# AI ANALYSIS - CLOUD (OpenAI) - OPTIONAL
# Get your API key from https://platform.openai.com/api-keys
# Cost: ~$0.0005 per analysis (~$0.50 per 1000 commits)
OPENAI_API_KEY=sk-your_openai_api_key_here

# AI ANALYSIS - LOCAL (Ollama) - OPTIONAL
# Use local open-source LLM (free, private, offline)
# Requires: Docker with Ollama, or local Ollama installation
# Setup: docker pull ollama/ollama && docker run -d -p 11434:11434 ollama/ollama
# Model: ollama pull mistral
USE_LOCAL_MODEL=false
OLLAMA_HOST=http://localhost:11434
LOCAL_MODEL=mistral

# Available local models (choose one):
# - mistral       (7B, super fast, good quality) ⭐⭐⭐⭐
# - neural-chat   (7B, optimized for chat) ⭐⭐⭐⭐
# - llama2        (7B/13B, highest quality) ⭐⭐⭐⭐⭐
# - dolphin-mixtral (8.7B, smart + fast) ⭐⭐⭐⭐⭐
# - openchat      (3.5B, ultra-light) ⭐⭐⭐
# - zephyr        (7B, good balance) ⭐⭐⭐⭐

# LOGGING CONFIGURATION
LOG_LEVEL=INFO

# DOCKER CONFIGURATION (optional)
DOCKER_REGISTRY=docker.io
DOCKER_IMAGE_TAG=latest

# ============================================================================
# QUICK START:
# 
# Option 1: OpenAI Cloud
#   1. Set OPENAI_API_KEY
#   2. Leave USE_LOCAL_MODEL=false
#   3. Bot uses GPT-3.5 for analysis
# 
# Option 2: Local Ollama (FREE)
#   1. docker pull ollama/ollama
#   2. docker run -d -p 11434:11434 ollama/ollama
#   3. docker exec ollama ollama pull mistral
#   4. Set USE_LOCAL_MODEL=true
#   5. Bot uses Mistral locally for analysis
# 
# Option 3: Hybrid (Smart)
#   1. Set OPENAI_API_KEY
#   2. Set USE_LOCAL_MODEL=true
#   3. Bot auto-selects: local for speed, OpenAI for quality
# 
# Option 4: Disabled
#   1. Leave both unset
#   2. AI analysis disabled (all other features work)
# 
# NOTE:
# - Change POSTGRES_PASSWORD to a strong unique password
# - Keep TELEGRAM_BOT_TOKEN, GITHUB_TOKEN, OPENAI_API_KEY private
# - DATABASE_URL auto-generated from other variables
# - LOCAL models require 4-8GB RAM
# - GPU support makes LOCAL models 5-10x faster
# ============================================================================
